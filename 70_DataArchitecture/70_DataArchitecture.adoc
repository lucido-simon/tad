= Data architecture =

== Introduction ==
One of the key components of a successful microservices implementation is a well-designed data architecture. This section of this paper will provide an in-depth examination of the various data architecture considerations that must be taken into account when designing and implementing microservices. We will begin by discussing the importance of data isolation and data consistency in a microservices environment. We will then explore different data storage options, such as relational databases, NoSQL databases, and in-memory databases, and their suitability for different types of microservices. We will also delve into the use of data caches, data replication, and data sharding to improve performance and availability. Finally, we will discuss how we can put into practice the theory we talked about by making a target architecture for our Polycode application. By the end of this section, readers should have a good understanding of the key data architecture considerations that must be taken into account when designing and implementing microservices, and be equipped with the knowledge to make informed decisions about data architecture in their own microservices projects, as well as a better understanding of my suggestions for Polycode.

=== Data architecture in microservices ===
They are some important concepts to understand when talking about data within a microservice architecture. We are going to go over them here, in order to lay some groundwork that we can then use to build suggestions and make informed decisions and criticisms of the solutions and patterns that we are going to explore during this section.

==== Data Isolation ====
Data isolation in a microservices architecture refers to the separation of data storage and access for each microservice. Each microservice should have its own data store, separate from other microservices, to make sure that changes made by one microservice do not affect the data of another microservice. This is important for several reasons:

* Decoupling: By isolating data, microservices can be developed and deployed independently, without the need for coordination with other microservices. This allows for more flexibility and faster development cycles.
* Scalability: Data isolation allows for each microservice to scale independently, without being constrained by the data storage requirements of other microservices.
* Security: Isolating data allows for better control over access to sensitive information.
* Data governance: Isolating data allows for better management and governance of data, as it is easier to understand and manage data when it is separated by service.

However, it is important to recognize that isolating data can make it more difficult to share data between microservices, and may require additional effort to maintain consistency across multiple data stores. As we are going to see later on, you may chose sacrifice your data isolation, as a trade-off for ease of access and consistency.

You can implement data isolation by having each microservice use its own database, or by partitioning a single database by service. This can be done by using database views, schema or by using different database technologies for different services. It's also important to consider eventual consistency when designing the data isolation.

==== Data consistency ====
Data consistency in a microservices architecture refers to the state of data across multiple microservices and data stores. In a microservices architecture, data is often distributed across multiple services, which can make it difficult to maintain consistency. When data is updated in one service, it may take some time for that change to propagate to other services and data stores, leading to inconsistencies.

[#consistencies]
There are different consistency models that can be used to maintain consistency in a microservices architecture:

* Strong consistency: With strong consistency, all services and data stores always have the same version of the data. This ensures that data is always consistent, but it can be difficult to achieve in a distributed system and leads to reduced performance.
* Eventual consistency: With eventual consistency, data is eventually consistent, meaning that it may take some time for all services and data stores to have the same version of the data. This model is more practical for distributed systems and can lead to better performance, but requires additional effort to handle conflicts and ensure that data is eventually consistent.
* Base consistency: With base consistency, data is consistent only at certain points in time, such as when a transaction is committed. This model can lead to reduced performance but can be easier to implement and may be sufficient for certain types of data.

Different microservices may require different consistency models. For example, a service handling financial transactions may require strong consistency, while a service handling user-generated content is usually able to use eventual consistency.

When designing a microservices architecture, consider the data consistency requirements of each service, and choose the appropriate consistency model for each service. It is also important to implement mechanisms such as distributed locks and versioning to handle conflicts and ensure consistency.

==== The CAP Theorem ====
The CAP theorem is a concept in distributed systems that states that it is impossible for a distributed system to simultaneously provide all three of the following guarantees:

* Consistency: All nodes in the system have the same data.
* Availability: Every request to the system receives a response, without guarantee that it contains the most recent version of the data.
* Partition tolerance: The system continues to function despite arbitrary partitioning due to network failures.

The CAP theorem states that a distributed system can only provide two of these guarantees at the same time. For example, a system that prioritizes consistency and availability can't tolerate network partitions, while a system that prioritizes availability and partition tolerance can't guarantee consistency.

image::70_DataArchitecture/70_CAP_Theorem.png[]

The CAP theorem is not a hard rule, but more of a guideline to help understand trade-offs of distributed systems. The theorem is a way to think about the different requirements of a system, and how the choices made for one aspect of the system may impact the others. 

When designing a distributed system, it's important to understand the requirements of the system and the trade-offs that must be made in terms of consistency, availability, and partition tolerance. This can help to make informed decisions about the architecture and technologies used in the system, and ensure that the system is able to meet the needs of the organization. 

The CAP Theorem is often used as a way to categorize databases solutions, and can play a role in choosing which database one will use. However, it is also useful when designing your data architecture system to better identify which of the previous characteristics you want to prioritize, and make the according decisions.

=== Relation with the microservice architecture ===
As you may have noticed, we already talked quite a lot about how we were going to architect our data within our system, during the first section of this paper, where we talked about how we can define our domains and microservices, with Polycode as support. We defined boundaries using both domain concerns, but also with transaction and consistency concerns.

Indeed, the data architecture for a microservices system should support the goals of the microservices architecture and vice-versa. We identified this relation, and made sure to create a microservice architecture that were driven by those concerns. We should have an easier time defining our data architecture, and actually already have a microservice architecture that allows some wiggle room to use different solutions in our Polycode system.

Before diving deeper in how we can architect our data within our system, I want to make a step back and firstly look at the databases technologies available on the market today, and where their use case makes sense.

== Different databases for different needs ==
In a microservices architecture, different microservices may have different data storage needs. Each type of database has its own set of strengths and weaknesses, and is better suited for certain types of data and workloads. In this chapter, I will explore the use cases, pros and cons of three types of databases: relational databases, document databases and in-memory databases. Each type of database has its own set of advantages and disadvantages. For example, document databases are good at handling flexible data models but doesn't provide the same level of performance as an in-memory database. On the other hand, relational databases provide robust querying capabilities but are not as well-suited for handling large amounts of unstructured data.

=== Relational databases ===
Relational databases are a type of database management system that store data in a structured format, using tables, rows, and columns. The most popular relational databases include MySQL, PostgreSQL, and Microsoft SQL Server.

Relational databases are based on the relational model, which is a mathematical model for representing data in a table-like format. Each table represents a specific entity, such as a user or a team, and each row represents an instance of that entity. The columns represent the attributes of the entity, such as the user's name or the team's captain. The relationships between entities are represented using foreign keys, which link rows in different tables together.

This type of databases are well-suited for applications that require complex querying and data relationships. The use of a relational model also allows for data validation and integrity constraints, which helps to ensure that the data stored in the database is correct and consistent.

Relational databases is usually queried using SQL, which is used to insert, update, retrieve and delete data from the database. SQL is a standard language that can be used across multiple relational databases.

However, relational databases are not always the best choice for every use case. They may not be as efficient as other types of databases at handling large amounts of unstructured data, and may not be able to scale as easily as some other types of databases, although we have some robust solutions nowadays. Additionally, the use of a fixed schema can make it more difficult to handle changes to the data model, and may require more effort to maintain backwards compatibility.

Overall, relational databases are a powerful and widely-used type of database management system, and are well-suited for applications that require complex querying and data relationships. However, it's important to carefully consider the specific needs of the application before choosing a relational database as the main data storage solution. In today's Polycode, we use relational database for storing users, teams, campaigns or transactions, since the schemas for those is well-defined, well-structured and present a strong relationship with other schemas in the database. We use PostgreSQL as our database solution.

=== Document databases ===
A document database is a type of NoSQL database that stores data in the form of documents, rather than tables and rows like in relational databases. The most popular document databases include MongoDB, Couchbase, and RavenDB.

Each document in a document database represents a single entity, such as a content or a module. The document can contain multiple fields, similar to columns in a relational database, to represent the attributes of the entity. Documents are stored in collections, similar to tables in a relational database. The collections can be searched and queried using a query language specific to the document database.

One of the main advantages of document databases is their ability to handle semi-structured or unstructured data. In contrast, relational databases rely on a fixed schema, which can make it difficult to handle changes to the data model. A document database can handle data fields that are missing or have different data types, and are more flexible when it comes to adding new fields or changing the structure of the data.

Another advantage of document databases is their ability to scale horizontally. They can handle high write loads and can easily scale by adding more machines to the cluster. This makes them a good choice for applications that have high write loads, need to handle large amounts of unstructured data, or need to scale quickly.

However, document databases have some trade-offs to consider as well. They doesn't provide the same level of performance as an in-memory database, and are not a good solution for handling complex data relationships as a relational database. Additionally, they doesn't provide the same level of data validation and integrity constraints as a relational database, which can lead to data inconsistencies.

In summary, document databases are a good choice for applications that require flexible data models, need to handle large amounts of unstructured data, or need to scale quickly. However, it's important to carefully consider the specific needs of the application before choosing a document database as the main data storage solution. We do use document database in the current state of Polycode, for storing contents, modules, submissions and validators for example. We use MongoDB as our document database solution.

=== In-memory databases ===
An in-memory database is a type of database management system that stores data in the main memory (RAM) of a computer, rather than on disk like traditional databases. This can make in-memory databases much faster than traditional databases, as data can be accessed and updated without the need for disk I/O. The most popular in-memory databases include Redis and Memcached.

In-memory databases are particularly well-suited for applications that require low-latency, high-performance data access. They are often used in applications such as real-time analytics, gaming, financial trading systems, and e-commerce platforms. For example, an in-memory database can be used to store real-time stock prices and perform real-time calculations on the data, or to store session data for a web application and quickly retrieve it for a user.

In-memory databases can be used as a caching layer between the application and a traditional database, to improve the performance of read-heavy workloads. They can also be used as a primary data store for write-heavy workloads, where data needs to be quickly accessed and updated.

In-memory databases usually provide a key-value data model, which allows for fast and efficient data access. They can also provide a data structure such as a hash table, list, or set, to support more advanced data manipulation.

However, in-memory databases also have some limitations to consider. They are typically more expensive than traditional disk-based databases, as they require more memory. Additionally, they are limited by the amount of memory available on a single machine, which can make it more difficult to scale the system horizontally. In-memory databases also typically do not provide the same level of durability as traditional databases, as data is lost when the system is powered off or crashes, even if modern in-memory that focuses on storing application data as a primary database, such as Redis, provides way to periodically flush its memory to the disk.

Overall, in-memory databases are a good choice for applications that require low-latency, high-performance data access and can afford the higher cost of memory. They are often used as a caching layer or a primary data store for write-heavy workloads. However, it's important to carefully consider the specific needs of the application before choosing an in-memory database as the main data storage solution. We do not use any in-memory database in the current state of Polycode. However, we have seen that we might have interest in using one in the runner architecture, and would make sense in other places, that we will discuss later.

Every types of databases have their strength and weaknesses, exacerbated by the fact that we are running in a microservice architecture. We are now going to explore what are the constraints that this brings onto our data architecture concerns.

== Availability and performance ==
When designing your data architecture, whatever the database type or solutions that you use, you need to think about the implications it will have on your overall system. In a microservice architecture, we want to scale, to be resilient and to be elastic. Performance is also a factor. Your data architecture needs to answer these constraints, else it will become a bottleneck in your system, since microservice are typically stateless, meaning that they can't function properly in any case if the underlying data layer is not operational.

In this chapter, I want to focus on some solutions that are available in most widely adopted systems, who helps solving these problems, as well as some patterns you can implement yourself for improving performance, reduce system load and overall improve your resiliency.

=== Data replication ===
Data replication is the process of copying data from one database to one or more other databases, to ensure that the data is available in multiple locations. Data replication is a key aspect of data architecture in microservices, as it can be used to improve the availability and performance of the system.

There are several types of data replication, each with its own set of advantages and use cases:

* Master-slave replication: In master-slave replication, one database server acts as the master and one or more other servers act as slaves. The master server receives write requests and updates the data, while the slaves replicate the data from the master and can be used to handle read requests. This type of replication is useful for improving read performance, as well as providing a backup in case the master server fails.
* Multi-master replication: In multi-master replication, multiple servers can act as both master and slave. This type of replication allows for multiple servers to handle write requests, which can improve write performance and provide a higher level of availability. However, it can also lead to conflicts when multiple servers try to update the same data at the same time.
* Global distributed replication: This type of replication is used to replicate data across multiple data centers in different geographic locations, which can improve performance by reducing the distance data has to travel, and also increase availability by providing a backup in case of a regional failure.

When choosing a data replication strategy, it's important to consider factors such as the consistency model, the network latency, the security of the data and the business continuity requirements. Additionally, it's important to consider the trade-offs between availability and consistency, as well as the cost of the replication solution. Different solutions might not provides all of these replication types, but you usually can find solutions in every type of database that fits your needs.

Overall, data replication is a powerful technique for improving the availability and performance of a microservices-based system. By replicating data across multiple locations, it can help to ensure that data is always available and can provide a backup in case of a failure.

=== Data sharding ===
Data sharding is a technique used to horizontally partition a large dataset and spread it across multiple servers, or shards. The goal of data sharding is to improve the performance, scalability, and availability of a system by distributing the data across multiple machines.

When a dataset becomes too large to fit on a single server, data sharding can be used to split the data into smaller, more manageable chunks called shards. Each shard is stored on a separate machine, and the data is distributed among them.

There are several strategies for data sharding:

* Range-based sharding: With range-based sharding, the data is partitioned based on a range of values, such as a date range or a numerical range. For example, all data with an ID between 1 and 10,000 could be stored on one shard, while data with an ID between 10,001 and 20,000 could be stored on another shard.
* Hash-based sharding: With hash-based sharding, a hash function is used to determine which shard a piece of data belongs to. The function takes a piece of data, such as a user ID, and maps it to a specific shard.
* Directory-based sharding: With directory-based sharding, a separate shard is designated as the directory and responsible for routing requests to the appropriate shard.
* Sharding by functionality: With sharding by functionality, data is partitioned based on the functionality of the application. For example, all data related to user accounts could be stored on one shard, while data related to product information could be stored on another shard.

Data sharding improves the performance, scalability and availability of a system by distributing the data across multiple machines, but it also comes with its own set of challenges. One of the main challenges is to ensure data consistency across the shards. This can be achieved by implementing a distributed transactional system, or by using a consistency model such as xref:consistencies[Base consistency or Eventual consistency].

Another challenge is to ensure that the sharding strategy is flexible enough to handle changes to the data, such as the addition or removal of shards.

In summary, data sharding is a powerful technique that can help to improve the performance, scalability, and availability of a system by distributing the data across multiple machines. However, it's important to carefully consider the specific needs of the application and to plan for the challenges that come with data sharding. Sharding is usually used in Document databases such as SQL, where the eventual consistency model is used. You can also find it in Redis.

=== Data caching ===
Data caching is a technique used to temporarily store frequently accessed data in a fast-access memory store, such as RAM, in order to speed up data retrieval and reduce the load on the underlying data store. Data caching is a key aspect of data architecture in microservices, as it can be used to improve the performance and scalability of the system.

There are several types of data caching:

* In-memory caching: This type of caching stores data in the main memory (RAM) of a machine. In-memory caching is the fastest type of caching, as data can be accessed and updated without the need for disk I/O. However, it is also the most expensive type of caching, as it requires more memory.
* Disk-based caching: This type of caching stores data on disk, typically in a file system or a specialized data store such as SQLite. Disk-based caching is slower than in-memory caching, but it is also less expensive, as it requires less memory.
* Distributed caching: This type of caching stores data across multiple machines, using a distributed cache management system such as Memcached or Redis. Distributed caching can improve scalability and availability, but it also requires more complex configuration and management.

When designing a caching strategy, it's important to consider factors such as the size of the cache, the expected cache hit rate, the eviction policy, and the cache invalidation strategy.

Cache eviction policy is a technique to decide which item should be removed from the cache when it is full and new items need to be added. Popular eviction policies include Least Recently Used (LRU), Least Frequently Used (LFU) and random eviction.

Cache invalidation strategy is a technique to decide when and how the cache should be updated. Popular invalidation strategies include time-based invalidation, where items are removed from the cache after a certain period of time, and event-based invalidation, where items are removed from the cache when certain events occur.

Another important consideration is the consistency model of the cache. A read-through cache will always read the data from the underlying data store and update the cache, while a write-through cache will always write the data to the underlying data store and the cache.

To my knowledge, there is no self-hosted solutions that provides a package that wraps both a document or relational database with a strong caching system in front. Introducing a cache layer in your system requires careful considerations about where you use this layer and when you fetch or mutate your data directly with the database. It also requires writing application specific code to handle cache misses and the caching process.

Overall, data caching is a powerful technique for improving the performance and scalability of a microservices-based system. By temporarily storing frequently accessed data in a fast-access memory store, it can help to reduce the load on the underlying data store and improve data retrieval times. However, it's important to carefully consider the specific needs of the application and plan for the challenges that come with data caching such as cache eviction and invalidation strategy, consistency model and the size of the cache.

== Architecture patterns ==
To better architect and standardized language between engineers, the system design community has defined multiple patterns that helps describing architectures, and how to solve certain problems. In this chapter, we will look at a few of them, with the advantages and drawbacks that comes with them.

=== Shared database pattern ===
The first pattern we are going to look at is the shared database pattern. As the name suggests, the shared database pattern is a microservices architecture pattern where multiple microservices share a single database. This pattern is useful when multiple microservices need to access the same data, and there is a need for consistency and transactional integrity across the data.

In this pattern, all microservices that need to access the same data are connected to the same database. Each microservice has its own schema, and the data is partitioned across different tables and rows. This allows each microservice to have its own set of tables, with its own data model, while still being able to access the shared data as needed.

One of the main advantages of the shared database pattern is that it allows for easy sharing of data across multiple microservices. It also allows for consistency and transactional integrity across the data, as all microservices are accessing the same database instance.

However, the shared database pattern also has some drawbacks to consider. One of the main drawbacks is that it leads to tight coupling between microservices, which make it difficult to change or evolve the system. Additionally, it can also lead to contention for resources and reduced scalability, as all microservices are accessing the same database instance.

To mitigate these risks, it's important to use a database that can handle the high read and write loads, and it's also important to plan for failover and replication. It's also important to carefully manage the data model and to use a database that supports data migrations. Lastly, it's important to monitor the database performance and to have a plan in place for dealing with bottlenecks or failures.

Another drawback is that it can lead to increased complexity in data management and data governance, as the shared data may be subject to multiple data models and data access patterns across different microservices, which may lead to conflicts and inconsistencies.

Overall, the shared database pattern is a useful pattern for microservices architecture when multiple microservices need to access the same data, and there is a need for consistency and transactional integrity across the data. However, it's important to carefully consider the specific needs of the application and to plan for the challenges that come with the shared database pattern. You might want to consider other approaches and resolve data consistency at the application level, rather than on the database level.

=== Database per Service pattern ===
The database per service pattern is a variation of the microservices architecture, where each service has its own dedicated database. Each service is responsible for its own data, and there is no sharing of data between services. This pattern can be useful when services have different data models and different performance requirements, and when data consistency across services is not a concern, or handled properly at the application layer.

One of the main advantages of the database per service pattern is that it allows for a high degree of autonomy and flexibility for each service. Each service can use a database that is best suited to its specific needs, and can evolve its data model independently of other services. Additionally, since each service has its own database, a failure or bottleneck in one service's database will not impact other services, which can improve availability and performance.

However, the database per service pattern also has some drawbacks. Since each service has its own database, there is no centralized query engine, which can make it more difficult to perform complex queries across services. Additionally, since each service has its own database, there is no centralized data management, which can make it more difficult to manage data consistency across services.

To mitigate this problems, creating a strong API systems between your microservices is important to be able to do advanced queries when required. Using a messaging system can be a powerful when you need to propagate events on your resources, so that services can notify each other of data changes and keep their databases in sync. It's also important to have a plan in place for dealing with data migrations and to monitor the performance of each service's database.

==== The saga pattern ====
I want to stop in this explanation of the database per service pattern to describe a pattern that helps resolving the data consistency problem: the saga pattern. The saga pattern is a way to handle long-running, complex transactions that involve multiple microservices in a distributed system. It is a way to ensure that a series of steps that need to be executed in a certain order are completed, even when individual steps fail.

The saga pattern is based on the idea that a long-running transaction can be broken down into a series of smaller, independent transactions, called sagas. Each saga represents a step in the overall process and is executed by a separate microservice. The sagas are orchestrated by a saga manager, which is responsible for coordinating the execution of the sagas, and for ensuring that the overall process is completed successfully, or that it is compensated in case of failure.

When a saga is executed, it may update the state of one or more services, and it may also publish events that are listened by other sagas. The events are used to trigger the next step in the process, or to trigger a compensation step in case of failure.

The saga pattern can be used to handle a wide variety of use cases, such as order processing, customer registration, and account management. It is used to make the state of the system always consistent, even in the presence of failures, and it can also be used to ensure that the system can be easily recovered in case of failures.

The saga pattern also has drawbacks, mostly in the form of complexity, especially when dealing with large and complex transactions. Additionally, it is difficult to test and debug, since it involves multiple microservices and a complex coordination mechanism. It also requires the implementation of a saga manager and a mechanism for storing and managing saga state.

In summary, the saga pattern is a way to handle long-running, complex transactions that involve multiple microservices in a distributed system. It is based on the idea of breaking a long-running transaction into smaller, independent transactions that are orchestrated by a saga manager. It can ensure that the state of the system is always consistent, even in the presence of failures, but it also has some drawbacks such as complexity to implement, test, and debug, and increase in system complexity. Let's now wrap up this chapter about the database per service pattern:

To sum up, the database per service pattern is a variation of the microservices architecture, where each service has its own dedicated database. It can be useful when services have different data models and different performance requirements, and when data consistency across services is not a concern. However, it also has some drawbacks, such as the difficulty of performing complex queries across services and the difficulty of managing data consistency across services. Careful planning and management are required to mitigate these risks.